#### 一、功能介绍
  主要实现了对东方财富网中策略研究和宏观报告页面中的研报信息的爬取，将研报文件下载到本地，并自动提取文本摘要（该功能待改进），文件和研报信息以邮件形式发送至指定邮箱，借助windows任务计划可每天定时获取最新研报，跟踪市场和研究动态。
  
#### 二、代码说明
##### 1.Crawler.py
##### 该部分代码主要实现爬虫功能，爬取研报的基本信息并下载文件到本地。
  研报的来源是东方财富网，网站中提供了免费且丰富的研报资源并支持手动下载研报文件，报告更新的频率还算及时且对各家机构均有覆盖。重要的是页面比较友好没有设置反爬，通过requests就可以直接爬取，
可以通过爬取指定日期的全部策略与宏观报告（修改setting.py中的开始和结束日期即可）。每次爬虫结束后会将本次爬取到的新报告信息补充输出到DownloadRecords.xlsx文件。
##### 2.MailSender.py
##### 该部分代码主要实现邮件发送功能。
  该功能主要为实现及时跟踪提醒的需求，会在每天定时完成爬取后通过邮件发送报告和信息。如果只想爬取一段日期内的研报至本地，可以将Crawler.py中DownloadReport函数的mail_sender关闭即可。
##### 3.PdfProcess.py
##### 该部分代码主要实现对pdf格式的研报进行文本提取。
  研报格式不一，但主要以pdf格式为主，该部分主要是将pdf格式研报中的文本内容提取出来，以用于提取文本摘要。python中有pdfminer模块可以直接提取pdf中的文字内容，但实际提取效果一般，因此采用了先将pdf转换成高像素图片，再借助百度OCR进行图片文本识别的方法，准确性有了较大的提高，而且百度OCR有基本识别5000图/天和高精度识别500图/天的免费使用额度，对单日的文本识别任务已经足够。
##### 4.FastTextRank4Sentence.py和util.py
##### 该部分代码主要实现自动提取文本摘要（待改进）。
  对于文本摘要的处理采用了TextRank算法，基本思想就是抽取重要性高的句子组成摘要，目前设置是返回抽取到的最重要的一句。但实际效果不算太好，一是耗时二是准确性，原因除了受算法本身限制外，也受到提取到的文本质量的影响，一是ocr图片识别准确率，二研报中往往有较多的图表识别提取后成为干扰文本需要处理，三是pdf提取的句子被换行强行拆分难以恢复成原本完整的句子。因此，该部分还需要进一步改进，可以设置setting.py中substract_option为False关闭提取摘要功能。
##### 5.MakeFiles.py
##### 该部分代码主要创建本地下载路径和研报粗分。
  根据研报的标题对研报类型进行粗分，一级分类：策略报告/宏观研究，二级分类：定期报告/深度专题/观察点评/科创板/海外，../定期报告下有三级分类：日报/周报/月报/季报年报，策略研究中的三级分类还包括金股。
##### 6.Setting.py
##### 该部分代码主要保存配置信息
  work_info包括本地存储路径、开始结束日期、报告类型、是否提取摘要；mail_info包括收件邮箱、发件邮箱、smtp授权码和smtp地址；baidu_info包括
  根据研报的标题对研报类型进行粗分，一级分类：策略报告/宏观研究，二级分类：定期报告/深度专题/观察点评/科创板/海外，../定期报告下有三级分类：日报/周报/月报/季报年报，策略研究中的三级分类还包括金股。
##### 7.Setup.py
##### 该部分代码主要用于运行

#### 三、注意事项：
1.运行前先打开Setting.py填写配置信息，其中开始结束日期格式为20200812，如果想实时抓取，都设置为time.strftime('%Y-%m-%d', time.localtime())即可；邮箱配置信息中的密码为smtp授权码并非登陆密码；百度api信息搜索百度智能云，创建一个文本识别应用就能获取到相关信息
2.定期运行的方法是借助windows中的任务计划，位置在我的电脑-右键-管理-任务计划程序-创建任务，触发器可以设置为10：00/12：00/16:00等等任意电脑开机的时间，操作中的程序脚本设置为setup.py文件
